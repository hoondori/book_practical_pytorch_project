{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c2e81cd",
   "metadata": {},
   "source": [
    "# 국민청원 분류하기\n",
    "\n",
    "- 페이지 크롤링\n",
    "- 전처리 \n",
    "- 단어임베딩\n",
    "- textCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4a7d74",
   "metadata": {},
   "source": [
    "# 크롤링 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3d790a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8438\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>category</th>\n",
       "      <th>count</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-08</td>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>인권/성평등</td>\n",
       "      <td>185</td>\n",
       "      <td>공문서와 인장을 불법위조를 하여 범죄혐의자를 무혐의처리 되도록 가짜문건을 만들어 행...</td>\n",
       "      <td>저는 전 정부하에 2013년 8월 12일\\r\\n수면제를 이용하여 범죄를 저지른 범죄...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-08</td>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>기타</td>\n",
       "      <td>883</td>\n",
       "      <td>방과후 강사들을 도와주세요.</td>\n",
       "      <td>초등학교 방과후 강사로 일하고 있는 사람입니다.\\r\\n지금 모든 학교가 온라인과 등...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-08</td>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>성장동력</td>\n",
       "      <td>170</td>\n",
       "      <td>과적.심청이 아부지법</td>\n",
       "      <td>존경할수 없는 대한민국 국회의원 법관 그리고 이나라의 대표 이신 대통령 저는 젊어서...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-08</td>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>육아/교육</td>\n",
       "      <td>779</td>\n",
       "      <td>대통령님 9살 아들죽인 계모때문에라도 사형제도 부활시켜주세요</td>\n",
       "      <td>대통령님\\r\\n지금 현재 대한민국이라는 나라는 처벌의 약함을 빌미로 \\r\\n사람을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-08</td>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>반려동물</td>\n",
       "      <td>19,027</td>\n",
       "      <td>계양산개농장철거!!!</td>\n",
       "      <td>안녕하세요!! 계양산으로 등산을 자주 가기도 했는데 뉴스로 충격적인 기사를 접해서 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        start         end category   count  \\\n",
       "0  2020-06-08  2020-07-08   인권/성평등     185   \n",
       "1  2020-06-08  2020-07-08       기타     883   \n",
       "2  2020-06-08  2020-07-08     성장동력     170   \n",
       "3  2020-06-08  2020-07-08    육아/교육     779   \n",
       "4  2020-06-08  2020-07-08     반려동물  19,027   \n",
       "\n",
       "                                               title  \\\n",
       "0  공문서와 인장을 불법위조를 하여 범죄혐의자를 무혐의처리 되도록 가짜문건을 만들어 행...   \n",
       "1                                    방과후 강사들을 도와주세요.   \n",
       "2                                        과적.심청이 아부지법   \n",
       "3                  대통령님 9살 아들죽인 계모때문에라도 사형제도 부활시켜주세요   \n",
       "4                                        계양산개농장철거!!!   \n",
       "\n",
       "                                             content  \n",
       "0  저는 전 정부하에 2013년 8월 12일\\r\\n수면제를 이용하여 범죄를 저지른 범죄...  \n",
       "1  초등학교 방과후 강사로 일하고 있는 사람입니다.\\r\\n지금 모든 학교가 온라인과 등...  \n",
       "2  존경할수 없는 대한민국 국회의원 법관 그리고 이나라의 대표 이신 대통령 저는 젊어서...  \n",
       "3  대통령님\\r\\n지금 현재 대한민국이라는 나라는 처벌의 약함을 빌미로 \\r\\n사람을 ...  \n",
       "4  안녕하세요!! 계양산으로 등산을 자주 가기도 했는데 뉴스로 충격적인 기사를 접해서 ...  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "csv_files = glob.glob(os.path.join('./crawl', \"*.csv\"))    \n",
    "df_from_each_file = (pd.read_csv(f) for f in csv_files)\n",
    "df = pd.concat(df_from_each_file, ignore_index=True)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396cba1f",
   "metadata": {},
   "source": [
    "# 데이터 전처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d9c80501",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'초등학교 방과후 강사로 일하고 있는 사람입니다.\\r\\n지금 모든 학교가 온라인과 등교 수업을 겸하고 있지만... 방과후 강사들의 일자리인 학교에서 당분간은 수업 진행이 힘들다는 통보만 받았습니다.1학기가 지나고 2학기가 시작된다 하여도 지금 현재로서는 어떠한 계획도 없는 상황이라고 합니다. 학교에서도 방과후 선생님들을 위해 등교도우미와 같은 일자리를 제공하고 있다고는 하지만 그것 조차도 뽑는 인원이 턱없이 적고..보수도 주14시간 미만으로만 일 할 수 있기에 방과후선생님들이 처한 경제적인 어려움에는 크게 도움이 되지 않습니다.\\r\\n저와 같이 생업으로 이 일을 하고 있는 많은 선생님들께서도 당장 매달 지출해야 하는 대출금이나 교육비 카드값등 나가는 돈들은 정해져 있는데...수입이 전혀 없는 상태로 지난 3개월을 버티는것 조차 쉬운일이 아니였습니다. 더는 버틸 수도 없고 앞날도 막막해진 이 시점에서 국민여러분들의 도움을 받고자 이 글을 쓰게 되었습니다.\\r\\n방과후 강사는 프리랜서 이기에 은행권'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1]['content'][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "65b13b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'초등학교 방과후 강사로 일하고 있는 사람입니다   지금 모든 학교가 온라인과 등교 수업을 겸하고 있지만  방과후 강사들의 일자리인 학교에서 당분간은 수업 진행이 힘들다는 통보만 받았습니다 1학기가 지나고 2학기가 시작된다 하여도 지금 현재로서는 어떠한 계획도 없는 상황이라고 합니다  학교에서도 방과후 선생님들을 위해 등교도우미와 같은 일자리를 제공하고 있다고는 하지만 그것 조차도 뽑는 인원이 턱없이 적고 보수도 주14시간 미만으로만 일 할 수 있기에 방과후선생님들이 처한 경제적인 어려움에는 크게 도움이 되지 않습니다   저와 같이 생업으로 이 일을 하고 있는 많은 선생님들께서도 당장 매달 지출해야 하는 대출금이나 교육비 카드값등 나가는 돈들은 정해져 있는데 수입이 전혀 없는 상태로 지난 3개월을 버티는것 조차 쉬운일이 아니였습니다  더는 버틸 수도 없고 앞날도 막막해진 이 시점에서 국민여러분들의 도움을 받고자 이 글을 쓰게 되었습니다   방과후 강사는 프리랜서 이기에 은행권 대출은 '"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_white_space(text):\n",
    "    text = re.sub(r'[\\t\\r\\n\\f\\v]', ' ', str(text))   # \\f :form feed   \\v : vertical tab\n",
    "    return text\n",
    "\n",
    "def remove_special_char(text):\n",
    "    text = re.sub('[^ ㄱ-ㅣ가-힣 0-9]+', ' ', str(text))  # 자음 : ㄱ-ㅎ, 모음 : ㅏ-ㅣ , 한글자:  가-힣, 숫자:0-9  이외에 제거 \n",
    "    return text\n",
    "\n",
    "remove_special_char(remove_white_space(df.loc[1]['content']))[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0e0df62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.title = df.title.apply(remove_white_space)\n",
    "df.title = df.title.apply(remove_special_char)\n",
    "\n",
    "df.content = df.content.apply(remove_white_space)\n",
    "df.content = df.content.apply(remove_special_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de3dbdf",
   "metadata": {},
   "source": [
    "# 토크나이징 및 변수 생성\n",
    "\n",
    "제목은 형태소 단위, 내용은 명사 단위, 명사만 추출해서 학습\n",
    "\n",
    "참고 : KoNLPy 한국어 처리 패키지\n",
    "* https://datascienceschool.net/03%20machine%20learning/03.01.02%20KoNLPy%20%ED%95%9C%EA%B5%AD%EC%96%B4%20%EC%B2%98%EB%A6%AC%20%ED%8C%A8%ED%82%A4%EC%A7%80.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295aa169",
   "metadata": {},
   "source": [
    "[토크나이징]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "998cecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "df['title_token'] = df.title.apply(okt.morphs)\n",
    "df['content_token'] = df.content.apply(okt.nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a2038e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>category</th>\n",
       "      <th>count</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>title_token</th>\n",
       "      <th>content_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-08</td>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>인권/성평등</td>\n",
       "      <td>185</td>\n",
       "      <td>공문서와 인장을 불법위조를 하여 범죄혐의자를 무혐의처리 되도록 가짜문건을 만들어 행...</td>\n",
       "      <td>저는 전 정부하에 2013년 8월 12일  수면제를 이용하여 범죄를 저지른 범죄혐의...</td>\n",
       "      <td>[공문서, 와, 인장, 을, 불법, 위조, 를, 하여, 범죄, 혐의, 자, 를, 무...</td>\n",
       "      <td>[저, 전, 정부, 수면제, 이용, 범죄, 범죄, 혐의, 명, 지방검찰청, 고소, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        start         end category count  \\\n",
       "0  2020-06-08  2020-07-08   인권/성평등   185   \n",
       "\n",
       "                                               title  \\\n",
       "0  공문서와 인장을 불법위조를 하여 범죄혐의자를 무혐의처리 되도록 가짜문건을 만들어 행...   \n",
       "\n",
       "                                             content  \\\n",
       "0  저는 전 정부하에 2013년 8월 12일  수면제를 이용하여 범죄를 저지른 범죄혐의...   \n",
       "\n",
       "                                         title_token  \\\n",
       "0  [공문서, 와, 인장, 을, 불법, 위조, 를, 하여, 범죄, 혐의, 자, 를, 무...   \n",
       "\n",
       "                                       content_token  \n",
       "0  [저, 전, 정부, 수면제, 이용, 범죄, 범죄, 혐의, 명, 지방검찰청, 고소, ...  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5b70c839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_pickle('temp/tokenized.pkl')   \n",
    "df = pd.read_pickle('temp/tokenized.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634052df",
   "metadata": {},
   "source": [
    "[파생변수 생성]\n",
    "\n",
    "[pandas serise string replace with regex](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.replace.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "69edc46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['token_final'] = df.title_token + df.content_token\n",
    "df['count'] = df['count'].replace({',':''}, regex = True).apply(lambda x: int(x))   # 문자화된 숫자를 숫자로 변경\n",
    "df['label'] = df['count'].apply(lambda x: 'Yes' if x >=1000 else 'No')\n",
    "\n",
    "df_drop = df[['token_final', 'label']]  # 머신러닝에 쓸 것만 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cf7dcc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_final</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[공문서, 와, 인장, 을, 불법, 위조, 를, 하여, 범죄, 혐의, 자, 를, 무...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[방과후, 강사, 들, 을, 도와주세요, 초등학교, 방과후, 강사, 일, 사람, 지...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[과, 적, 심청, 이, 아부, 지법, 존경, 대한민국, 국회의원, 법관, 이나라,...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[대통령, 님, 9, 살, 아들, 죽인, 계모, 때문, 에라도, 사형제, 도, 부활...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[계양산, 개, 농장, 철거, 계양산, 등산, 자주, 가기, 뉴스, 충격, 기사, ...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         token_final label\n",
       "0  [공문서, 와, 인장, 을, 불법, 위조, 를, 하여, 범죄, 혐의, 자, 를, 무...    No\n",
       "1  [방과후, 강사, 들, 을, 도와주세요, 초등학교, 방과후, 강사, 일, 사람, 지...    No\n",
       "2  [과, 적, 심청, 이, 아부, 지법, 존경, 대한민국, 국회의원, 법관, 이나라,...    No\n",
       "3  [대통령, 님, 9, 살, 아들, 죽인, 계모, 때문, 에라도, 사형제, 도, 부활...    No\n",
       "4  [계양산, 개, 농장, 철거, 계양산, 등산, 자주, 가기, 뉴스, 충격, 기사, ...   Yes"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d032c7",
   "metadata": {},
   "source": [
    "[단어 임베딩] : [gensim.Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html) skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "14db54d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=40581, size=100, alpha=0.025)\n",
      "[('음주', 0.8935098052024841), ('뺑소니', 0.848153829574585), ('살인마', 0.7900915741920471), ('무면허', 0.789531409740448), ('절도', 0.7880804538726807), ('스토킹', 0.7821337580680847), ('동물학대', 0.7699282169342041), ('강력범죄', 0.7664657831192017), ('검거', 0.7615181803703308), ('싸이코패스', 0.7603848576545715)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# 생성\n",
    "embedding_model = Word2Vec(\n",
    "    df_drop['token_final'], \n",
    "    sg = 1, # skip-gram\n",
    "    size = 100,\n",
    "    window = 2,\n",
    "    min_count = 1,\n",
    "    workers = 4\n",
    ")\n",
    "print(embedding_model)\n",
    "\n",
    "# 저장\n",
    "embedding_model.wv.save_word2vec_format('data/petitions_tokens_w2v')\n",
    "\n",
    "# 사용\n",
    "loaded_model = KeyedVectors.load_word2vec_format('data/petitions_tokens_w2v')\n",
    "model_result = embedding_model.wv.most_similar(\"음주운전\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624bbddb",
   "metadata": {},
   "source": [
    "[데이터셋 분할 및 저장]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9a08f27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "rng = RandomState()\n",
    "\n",
    "tr = df_drop.sample(frac=0.8, random_state=rng)\n",
    "val = df_drop.loc[~df_drop.index.isin(tr.index)]\n",
    "\n",
    "assert tr.index.size + val.index.size == len(df_drop)\n",
    "\n",
    "tr.to_csv('data/train.csv', index=False, encoding='utf-8-sig')\n",
    "val.to_csv('data/validation.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc8e293",
   "metadata": {},
   "source": [
    "[Field 클래스 정의] : torchtext.Field\n",
    " - [use legacy](https://github.com/pytorch/text/blob/master/examples/legacy_tutorial/migration_tutorial.ipynb)\n",
    "\n",
    "[dataset 만들기] [torchtext.data](https://torchtext.readthedocs.io/en/latest/data.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d18277f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ['들', '방통위', '을', '처벌', '해주세요', '개그우먼', '씨', '나', '혼자', '방송'], No\n",
      "validation: ['사업', '부도', '와', '국세', '행정', '안녕', '격무', '노고', '저', '최'] No\n"
     ]
    }
   ],
   "source": [
    "import torchtext\n",
    "from torchtext.legacy.data import Field, TabularDataset\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('[\\[\\]\\']', '', str(text))   # 대괄호, ' 제거\n",
    "    text = text.split(', ')\n",
    "    return text\n",
    "\n",
    "TEXT = Field(tokenize=tokenizer)\n",
    "LABEL = Field(sequential = False)\n",
    "\n",
    "train, validation = TabularDataset.splits(\n",
    "    path = 'data/',\n",
    "    train = 'train.csv',\n",
    "    validation = 'validation.csv',\n",
    "    format = 'csv',\n",
    "    fields = [('text', TEXT), ('label', LABEL)],\n",
    "    skip_header = True\n",
    ")\n",
    "\n",
    "print('Train: {}, {}'.format(train[0].text[:10], train[0].label))\n",
    "print('validation: {} {}'.format(validation[0].text[:10], validation[0].label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f856887e",
   "metadata": {},
   "source": [
    "[단어장 및 datasetloader 정의] : [torchtext.vocab](https://torchtext.readthedocs.io/en/latest/vocab.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "90cdaed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding dim: torch.Size([35644, 100])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.legacy.vocab import Vectors\n",
    "from torchtext.legacy.data import BucketIterator\n",
    "\n",
    "vectors = Vectors(name='data/petitions_tokens_w2v')\n",
    "TEXT.build_vocab(train, # dataset\n",
    "                 # followings are passed to constructor of Vocab\n",
    "                 vectors = vectors, min_freq = 1, max_size = None)\n",
    "\n",
    "LABEL.build_vocab(train)\n",
    "vocab = TEXT.vocab\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iter, validation_iter = BucketIterator.splits(\n",
    "    datasets = (train, validation),\n",
    "    batch_size = 8,\n",
    "    device = device,\n",
    "    sort = False\n",
    ")\n",
    "\n",
    "print('embedding dim: {}'.format(TEXT.vocab.vectors.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58a7e44",
   "metadata": {},
   "source": [
    "[TextCNN 모델링]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b828abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TextCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_built, emb_dim, dim_channel, kernel_wins, num_class):\n",
    "        super(TextCNN, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(len(vocab_built), emb_dim)\n",
    "        self.embed.weight.data.copy_(vocab_built.vectors)   # 기 형성된 word2vec 데이터 셋팅\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, dim_channel, (w, emb_dim)) for w in kernel_wins])   # conv2d variable-kernel parallel\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc = nn.Linear(len(kernel_wins)*dim_channel, num_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch, max_len)\n",
    "\n",
    "        emb_x = self.embed(x)   # (batch, max_len, emb_dim)\n",
    "        emb_x = emb_x.unsqueeze(1)  # (batch, 1, max_len, emb_dim)\n",
    "\n",
    "        conv_x = [self.relu(conv(emb_x)) for conv in self.convs]   # 커널수만큼  parallel, (batch, out_channel=10, max_len', 1)\n",
    "        pool_x = [F.max_pool1d(x.squeeze(-1), x.size()[2]) for x in conv_x]    # 각 channel 에서 max element 1개 추출 \n",
    "                                                                               # (batch, out_channel, 1)\n",
    "        \n",
    "        fc_x = torch.cat(pool_x, dim=1) # (batch, n_kernel*out_channel, 1)\n",
    "        fc_x = fc_x.squeeze(-1) # (batch, n_kernel*out_channel)\n",
    "        fc_x = self.dropout(fc_x)\n",
    "        \n",
    "        logit = self.fc(fc_x)  # (batch, n_kernel*out_channel)\n",
    "\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fa964b",
   "metadata": {},
   "source": [
    "[모델 학습/평가 함수]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3c19e472",
   "metadata": {
    "code_folding": [
     0,
     28
    ]
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_itr, optimizer):\n",
    "    \n",
    "    model.train()                               \n",
    "    corrects, train_loss = 0.0,0        \n",
    "    \n",
    "    for batch in train_itr:\n",
    "        \n",
    "        text, target = batch.text, batch.label      \n",
    "        text = torch.transpose(text, 0, 1)          \n",
    "        target.data.sub_(1)                                 \n",
    "        text, target = text.to(device), target.to(device)  \n",
    "\n",
    "        optimizer.zero_grad()                           \n",
    "        logit = model(text)                         \n",
    "    \n",
    "        loss = F.cross_entropy(logit, target)   \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        \n",
    "        train_loss += loss.item()    \n",
    "        result = torch.max(logit,1)[1] \n",
    "        corrects += (result.view(target.size()).data == target.data).sum()\n",
    "        \n",
    "    train_loss /= len(train_itr.dataset)\n",
    "    accuracy = 100.0 * corrects / len(train_itr.dataset)\n",
    "\n",
    "    return train_loss, accuracy\n",
    "\n",
    "def evaluate(model, device, itr):\n",
    "    \n",
    "    model.eval()\n",
    "    corrects, test_loss = 0.0, 0\n",
    "\n",
    "    for batch in itr:\n",
    "        \n",
    "        text = batch.text\n",
    "        target = batch.label\n",
    "        text = torch.transpose(text, 0, 1)\n",
    "        target.data.sub_(1)\n",
    "        text, target = text.to(device), target.to(device)\n",
    "        \n",
    "        logit = model(text)\n",
    "        loss = F.cross_entropy(logit, target)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        result = torch.max(logit,1)[1]\n",
    "        corrects += (result.view(target.size()).data == target.data).sum()\n",
    "\n",
    "    test_loss /= len(itr.dataset) \n",
    "    accuracy = 100.0 * corrects / len(itr.dataset)\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6cab25",
   "metadata": {},
   "source": [
    "[모델 학습 및 성능 확인]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0325bec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 \t Loss: 0.08552285376301519 \t Accuracy: 56.20740509033203%\n",
      "Valid Epoch: 1 \t Loss: 0.08501673157887436 \t Accuracy: 57.34597396850586%\n",
      "model saves at 57.34597396850586 accuracy\n",
      "--------------------------------------------------------\n",
      "Train Epoch: 2 \t Loss: 0.08295263561054513 \t Accuracy: 59.762962341308594%\n",
      "Valid Epoch: 2 \t Loss: 0.079980618986897 \t Accuracy: 62.500003814697266%\n",
      "model saves at 62.500003814697266 accuracy\n",
      "--------------------------------------------------------\n",
      "Train Epoch: 3 \t Loss: 0.064539615171927 \t Accuracy: 75.37777709960938%\n",
      "Valid Epoch: 3 \t Loss: 0.08391831311180976 \t Accuracy: 62.914695739746094%\n",
      "model saves at 62.914695739746094 accuracy\n",
      "--------------------------------------------------------\n",
      "Train Epoch: 4 \t Loss: 0.031169164081552514 \t Accuracy: 90.45925903320312%\n",
      "Valid Epoch: 4 \t Loss: 0.10983274719055512 \t Accuracy: 62.44076156616211%\n",
      "--------------------------------------------------------\n",
      "Train Epoch: 5 \t Loss: 0.013412517882780068 \t Accuracy: 96.25184631347656%\n",
      "Valid Epoch: 5 \t Loss: 0.13872726441700878 \t Accuracy: 61.37440872192383%\n",
      "--------------------------------------------------------\n",
      "Train Epoch: 6 \t Loss: 0.006942565613573943 \t Accuracy: 97.97036743164062%\n",
      "Valid Epoch: 6 \t Loss: 0.16283043135416592 \t Accuracy: 61.789100646972656%\n",
      "--------------------------------------------------------\n",
      "Train Epoch: 7 \t Loss: 0.004829839033741842 \t Accuracy: 98.81481170654297%\n",
      "Valid Epoch: 7 \t Loss: 0.1879798242098418 \t Accuracy: 60.84123611450195%\n",
      "--------------------------------------------------------\n",
      "Train Epoch: 8 \t Loss: 0.0035199564175349795 \t Accuracy: 99.0962905883789%\n",
      "Valid Epoch: 8 \t Loss: 0.20337992011772477 \t Accuracy: 61.018959045410156%\n",
      "--------------------------------------------------------\n",
      "Train Epoch: 9 \t Loss: 0.0030886789474956528 \t Accuracy: 99.24444580078125%\n",
      "Valid Epoch: 9 \t Loss: 0.22254283424638988 \t Accuracy: 61.31516647338867%\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = TextCNN(vocab, 100, 10, [3,4,5], 2).to(device)\n",
    "#print(model)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "best_test_acc = -1\n",
    "for epoch in range(1, 10):\n",
    "    \n",
    "    tr_loss, tr_acc = train(model, device, train_iter, optimizer)\n",
    "    print('Train Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, tr_loss, tr_acc))\n",
    "    \n",
    "    val_loss, val_acc = evaluate(model, device, validation_iter)\n",
    "    print('Valid Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, val_loss, val_acc))\n",
    "    \n",
    "    if val_acc > best_test_acc:\n",
    "        best_test_acc = val_acc\n",
    "        \n",
    "        print(\"model saves at {} accuracy\".format(best_test_acc))\n",
    "        torch.save(model.state_dict(), \"TextCNN_BEST_validation.model\")\n",
    "        \n",
    "    print('--------------------------------------------------------')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881f3cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai2)",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
